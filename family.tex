%!TEX root = main.tex

\section{The family of distributions $\mathcal{W}$}
\label{sec:family}
Our main results show the impossibility of constructing fuzzy extractors for the family of distributions $\mathcal{W}$ of $2^k$ random points sampled from $\zo^n$ (without replacement).  Unfortunately, there are distributions $W_Z$ for some values $Z$ that do not have fuzzy min-entropy so there is no reason to expect a fuzzy extractor to be able to secure these distributions.  However, below we show a closely related family of distributions where all $W_Z$ have fuzzy min-entropy that is statistically close to $k$ random points.

\input{sampling}

%\begin{definition}[Markov's Inequality]
%    Markov's inequality is a tail bound for random variables that gives an upper bound on the probability of a random variable deviating from its mean. Let $\Pr[X>0] = 1$. Then the following inequality holds for any $\alpha > 0$: 
%    \[ 
%      \Prob{X \geq \alpha \cdot \Ex{X}} \leq 1/\alpha .
%    \]
%\end{definition}


%\subsection{Conditional Min-Entropy Technical Results}
%It has been shown that universal fuzzy extractors are impossible in the information theoretic setting. 
%
%\subsection{Average Conditional Min-Entropy Loss}
%
%
%\begin{proof}
%    Since each $X_i$ is independent then $\minent{\vec{X}} = \sum \minent{X_i}$.
%    Now, by definition,
%    \begin{align*}
%        \acminent{\vec{X}}{Y} &= -\log{\Exlim{y \leftarrow Y}{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x}\ |\ Y = y}}} \\
%        &= -\log{\sum\limits_{y} \max\limits_{\vec{x}} \Prob{\vec{X} = \vec{x} \ |\ Y = y} \cdot \Prob{Y = y}}\\
%        &= -\log{\sum\limits_{y} \max\limits_{\vec{x}} \Prob{\vec{X} = \vec{x} \vee Y = y}}\\
%        &\geq -\log{\sum\limits_{y} \max\limits_{\vec{x}, y'} \Prob{\vec{X} = \vec{x}  \wedge Y = y'}}\\
%        &= -\log{2^{\hart{Y}} \cdot 2^{\minent{\vec{X},Y}}}\\
%        &= \minent{\vec{X},Y} - \hart{Y}\\
%        &\geq \minent{\vec{X}} - \hart{Y} \\   
%        &= \sum \minent{X_i} - \hart{Y}
%    \end{align*}
%\end{proof}
%
%\subsubsection{Markov Bound for Predictability}
%Markov bounds are tail bounds that use Markov's Inequality to bound the probability that a random variable deviates significantly from its expected value. In Markov's inequality, we necessarily lose a multiplicative factor (here called $alpha$) in order to control the probability of the event occuring. When discussing entropy, we are dealing with a log scaled value which makes losing multiplicative factors costly. Instead, we can perform a Markov bound on the predictability scale. In this case, rather than lose a multiplicative factor in entropy, we lose a multiplicative factor in predictability which translates to a small number of bits of entropy lost for the controlled outcomes.
%
%

%\begin{align*}
%    \acminent{\vec{X}}{Y} &= \Delta\\
%    -\log{\Exlim{Y}{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x} \,|\, Y = y}}} &= \Delta\\
%    \Exlim{Y}{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x} \,|\, Y = y}} &= 2^{-\Delta}\\
%    \Problim{Y}{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x} \,|\, Y = y} \geq \alpha \cdot 2^{-\Delta}} &\leq \frac{1}{\alpha} \\
%    \Problim{Y}{\log{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x} \,|\, Y = y}} \geq \log{\alpha} -\Delta} &\leq \frac{1}{\alpha} \\
%    \Problim{Y}{-\log{\max\limits_{\vec{x}} \Prob{\Vec{X} = \vec{x} \,|\, Y = y}} < \Delta -\log{\alpha}} &\leq \frac{1}{\alpha} \\
%    \Problim{y\leftarrow Y}{\minent{\vec{X}\, |\, Y=y} < \Delta -\log{\alpha}} &\leq \frac{1}{\alpha}
%\end{align*}
