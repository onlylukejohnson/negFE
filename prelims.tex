%!TEX root = main.tex
% Preliminary Definitions and Results for negFE

\section{Preliminaries}
\label{sec:prelim}
For distributions $X, Y$ over the same discrete domain,
\[
\Delta(X, Y)\overset{def}= \frac{1}{2}\sum_{x \in X} \left| \Pr[X=x] - \Pr[Y=y]\right|.
\]
For a metric space $(\mathcal{M}, \dis)$ let $B_t(x) = \{y | \dis(x, y)\le t\}$. If the size of $B_t(x)$ is the same for all points $x$ we use $|B_t|$ to denote this quantity and say that the \emph{size of balls is center independent}.  All logarithms are base $2$.

This work considers the possibility of constructing fuzzy extractors from a finite family of distributions that we will call $\mathcal{W}$. 
Throughout, we will need the ability to describe a particular value in this family.  
We let $Z$ be an index for the distributions in the family and we denote a distribution as $W_Z$. 
The distribution $W_Z$ can then be sampled, and we denote a sample of $w\leftarrow W_Z$ where  $w \in \zeroone{n}$.

\subsection{Notions of Entropy}
    \textbf{Entropy}, denoted $\ent{X}$, for some discrete random variable $X$ is $\ent{X} \defined \expe_x\left[-\log{\Pr[X=x]}\right]$. 
    For a random variable $X$ whose outcomes are in $\{0,1\}$, let $\Pr[X=1] = p$. The \textbf{binary entropy} of $X$ is  $h_2(X) :=H(X)=-p\cdot\log{p} - (1-p)\cdot\log{1-p}.$ 
For a discrete random variable $X$, 
    \textbf{min-entropy} is $\minent{X} \defined -\log{\max_{x_i} \Pr(X=x_i)}$.  
%For a discrete random variable $X$ \textbf{Hartley entropy}, denoted $\hart{X}$ is 
%$  \hart{X} = | \sbr{x \in X\,|\, \Prob{X = x} > 0}|.
%  $
\begin{definition}[Average Min Entropy]
Let $X$ be a discrete random variable and let $Y$ be a random variable.  The \emph{average min-entropy} of $X|Y$ is  \[ \acminent{X}{Y} \defined -\log{\Exlim{y \leftarrow Y}{\max\limits_{x} \Prob{X = x\ |\ Y = y}}}.\] 
\end{definition}

\begin{definition}[Smooth Conditional Min Entropy~\cite{renner2005simple}]
    \emph{Smooth Conditional Min Entropy}, denoted $\Haveps(X|Y)$ for two random variables $X$ and $Y$ is \[\Haveps(X|Y):=\max_{(X',Y') | \Delta((X', Y'), (X, Y))\le \epsilon} \acminent{X'}{Y'}.
    \] 
\end{definition}

The above definition combines definitions from Renner and Wolf~\cite{renner2005simple} and Dodis et al.~\cite{dodis2008fuzzy}.  Renner and Wolf's definition considers the worst case $Y$.  We focus on the average case $Y$ because the above definition suffices for randomness extraction.



%\begin{lemma}
%    \label{lem:conditionalminentloss}
%    Let $\vec{X} = (X_1, X_2, \ldots, X_k)$ be independent random variables. 
%    Let $Y$ be a random variable arbitrarily correlated with $\vec{X}$. 
%    Then 
%    \[
%        \acminent{\vec{X}}{Y} \geq \minent{\vec{X}} - \hart{Y} = \sum \minent{X_i} - \hart{Y}
%    \]
%\end{lemma} 
%\noindent
%Lemma~\ref{lem:conditionalminentloss} follows by \cite[Lemma 2.2b]{dodis2008fuzzy} and independence of the $X_i$.



\subsection{Fuzzy Min-Entropy and Hamming Balls}
\begin{definition}[Fuzzy min-entropy~\cite{fuller2020fuzzy}]

For a distribution $W$ and a distance parameter $t$, the fuzzy min-entropy of $W$, denoted $\Hfuzz(W)$ is 
\[
\Hfuzz(W):= -\log{ \max_{w^*} \left(\sum_{w, \dis(w, w^*)\le t} \Pr[W=w] \right)}.
\]
\end{definition}

\begin{proposition} \label{lem:max fuzz ent}
For all distributions $W$ over a metric space $(\mathcal{M}, \dis)$, 
\[\Hfuzz(W) \le \log{|\mathcal{M}|} - \log{|B_t|}.
\]
\end{proposition}
\noindent
For $\mathcal{M} = \zo^n$ and the binary Hamming metric,
Using Ash~\cite[Lemma 4.7.2, Equation 4.7.5, p. 115]{ash2012information} one has
\begin{align} nh_2(t/n)  -1/2\log{n} - 1/2 \le \log{|B_t|} \le  nh_2(t/n)\label{eq:size of balls}.\end{align}
and thus, 
\[
\Hfuzz(W) \le \log{|\mathcal{M}|} - \log{|B_t|}\le n\left(1-h_2\left(\frac{t}{n}\right)\right)+ \frac{\log{n}}{2} +1/2.
\]

\noindent
We now introduce the notion of $\beta$-density which measures the size of a Hamming ball in comparison to the whole metric space.
\begin{definition}
Let $(\mathcal{M}, \dis)$ be a metric space where the size of balls is center independent.  The $\beta$ density is
\[
\beta := \log{\frac{|\mathcal{M}|- |B_t|}{|B_t|}} 
\]
\label{def:b density}
\end{definition}
\begin{claim} 
For the binary Hamming metric over $\zo^n$ for $t<n/2$
\[
<<<<<<< HEAD
n\left(1-h_2\left(\frac{t}{n}\right)\right)-1 \le \beta \le n\left(1-h_2\left(\frac{t}{n}\right)\right)+\frac{\log{n}}{2}+\frac{1}{2}.
=======
n\left(1-h_2\left(\frac{t}{n}\right)\right)+\frac{\log{n}}{2}+\frac{1}{2} \ge \beta \ge n\left(1-h_2\left(\frac{t}{n}\right)\right)-1.
>>>>>>> 7eeb40e956de3b97104aefdf518a9c4153a8314c
\]

\end{claim}

\begin{proof}
By Equation~\ref{eq:size of balls} one has: 
\begin{align*}
\beta & = \log{\frac{2^n}{|B_t|} -1} \le \log{2^{n\left(1-h_2\left(\frac{t}{n}\right)\right) + 1/2 \log{n}+1/2} -1} \le n\left(1-h_2\left(\frac{t}{n}\right)\right) + \frac{1}{2}\log{n}+ \frac{1}{2}\\
\beta&\ge \log{2^{n\left(1-h_2\left(\frac{t}{n}\right)\right)} -1} \ge \log{2^{n\left(1-h_2\left(\frac{t}{n}\right)\right)-1} } \ge n(1-h_2(t/n))-1.
\end{align*}
\end{proof}


    \subsection{Fuzzy Extractors and Secure Sketches}
\begin{definition}[Secure Sketch~\cite{dodis2008fuzzy}]
For metric space $(\mathcal{M}, \dis)$ and distribution $W$ with probability mass function $z$, a $(\mathcal{M}, \tilde{m}, t, \epsilon, \delta, \ell)$-\emph{secure sketch} is a pair of algorithms $(\sketch_z, \rec_z)$ with the following properties 
\begin{enumerate} 
\itemsep0em
\item \textbf{Correctness} For all $w, w'$ such that $\dis(w, w')$, then $\Pr_{ss \leftarrow \sketch(w)}[\rec_z(w', ss) = w]\ge 1-\delta.$
\item \textbf{Security}  $\Haveps(W | \sketch_z(W)) \ge \tilde{m}$.
\item \textbf{Space Bounded} The circuits $\sketch_z$ and $\rec_z$ require at most $\ell$ bits to describe.  That is, $|\sketch_z| +|\rec_z|\le \ell$.
\end{enumerate}
\end{definition}

\paragraph{The use of smooth min-entropy} In the above, the secure sketch is required to retain smooth conditional min-entropy of $W$ conditioned on the sketch.  Many definitions consider $\epsilon=0$ or average min-entropy.  However, smooth min-entropy is the necessary and sufficient condition for privacy amplification through the use of an average-case randomness extractor~\cite{renner2005simple}.

\begin{definition}[Fuzzy Extractor~\cite{dodis2008fuzzy}]
For metric space $(\mathcal{M}, \dis)$ and probability distribution $W$ with probability mass function $z$, a $(\mathcal{M}, \kappa, t, \epsilon)$-\emph{fuzzy extractor} is a pair of algorithms $(\gen_z, \rep_z)$ with the following properties 
\begin{enumerate} 
\itemsep0em
\item \textbf{Correctness} For all $w, w'$ such that $\dis(w, w')$, then 
$\Pr_{r, p \leftarrow \gen(w)}[\rep(w', p) = r]=1.$ 
\item \textbf{Security} Let $R, P \leftarrow \gen_z(W)$ and $U_\kappa$ be a uniformly distributed random variable over $\zo^\kappa$, $\Delta((R, P), (U_\kappa, P))\le \epsilon.$
\item  \textbf{Space Bounded} The circuits $\gen_z$ and $\rep_z$ require $\ell$ bits to describe.  That is, $|\gen| +|\rec|\le \ell$.
\end{enumerate}
\label{def:fe}
\end{definition}

\noindent
We now define fuzzy extractors and secure sketches with advice.  This is an intermediate definition that will be used in proofs throughout.  As we show in Lemmas~\ref{lem:distributional advise suffices} and \ref{lem:distributional advise suffices ss}, the impossibility of building a fuzzy extractor (resp. secure sketch) with advice for a family $\mathcal{W}$ implies the impossibility of building a fuzzy extractor (resp. secure sketch) for many $W_Z\in\mathcal{W}$.

\begin{definition}[Secure Sketch with distributional advice]
\label{def:ss distributional}
Let $\mathcal{W}$ be a family of distributions indexed by $z$.  That is, denote each distribution in $\mathcal{W}$ as $W_Z$ with $Z$ describing the probability mass function of $W$.  
For metric space $(\{0,1\}^n, \dis)$, a $(\{0,1\}^n, \mathcal{W}, \tilde{m}, t, \epsilon, \delta, \ell)$-\emph{secure sketch with distributional advice} is a triple of algorithms $(\gen, \rep, \aux)$ with the following properties:
\begin{enumerate} 
\itemsep0em
\item \textbf{Correctness} For all $w, w'$ such that $\dis(w, w')$, let $\Pr_{ss \leftarrow \sketch(w)}[\rec(w', ss) = w]\ge 1-\delta.$
\item \textbf{Security} Let $\aux$ be a deterministic function with output in $\zo^\ell$.  For all distributions $W_Z \in \mathcal{W}$, define $\advice_Z:= \aux(Z)$ and let $ss \leftarrow \sketch(W_Z, \advice_Z)$. Then,
$
\expe_{Z} [\Haveps(W_Z| ss)] \ge \tilde{m}.
$
\end{enumerate}
\end{definition}


\begin{definition}[Fuzzy Extractor with distributional advice]
\label{def:fe distributional}
Let $\mathcal{W}$ be a family of distributions indexed by $z$.  That is, denote each distribution in $\mathcal{W}$ as $W_Z$ with $Z$ describing the probability mass function of $W$.  
For metric space $(\{0,1\}^n, \dis)$, a $(\{0,1\}^n, \mathcal{W}, \kappa, t, \epsilon, \ell)$-\emph{fuzzy extractor with distributional advice} is a triple of algorithms $(\gen, \rep, \aux)$ with the following properties:
\begin{enumerate} 
\itemsep0em
\item \textbf{Correctness} For all $w, w'$ such that $\dis(w, w')$, let $\Pr_{(r, p) \leftarrow \gen(w)}[\rep(w', p) = r]=1.$
\item \textbf{Security} Let $\aux$ be a deterministic function with output in $\zo^\ell$.  For a distribution $W_Z \in \mathcal{W}$, define $\advice_Z:= \aux(Z)$, let $(R, P) \leftarrow \gen(W, \advice_Z)$ and $U_\kappa$ be a uniformly distributed random variable over $\zo^\kappa$ it holds that $\Delta((R, P, Z), (U_\kappa, P, Z))\le \epsilon.$
\end{enumerate}
\end{definition}

\begin{lemma}

Let $\mathcal{W}$ be a distribution family indexed by the set $Z$ and suppose that no $(\mathcal{M}, \mathcal{W}, \kappa, t, \epsilon, \ell)$-fuzzy extractor with distributional advice exists.  For all families $\mathcal{W}'\subseteq \mathcal{W}$ indexed by $Z'\subseteq Z$ where \[\frac{|Z'\cap Z|}{|Z|} = \frac{|Z'|}{|Z|}\le 1-\zeta\] there is some $Z'$ there is no  $(\{0,1\}^n,\kappa, t, (\epsilon-\zeta))/(1-\zeta), \ell)$ fuzzy extractor $(\gen_Z, \rep_Z)$.
\label{lem:distributional advise suffices}
\end{lemma}
\begin{proof}[Proof of Lemma~\ref{lem:distributional advise suffices}]
We proceed by contrapositive.  Let $\mathcal{W}'$ be some subset of $\mathcal{W}$ with relative size at least $1-\zeta$ where  for every $W_Z\in\mathcal{W}'$ there exists an $(\{0,1\}^n,\kappa, t, (\epsilon-\zeta)/(1-\zeta), \ell)$-fuzzy extractor.  We denote these algorithms by $(\gen_Z, \rep_Z)$ respectively.  We now describe how to build the fuzzy extractor $(\gen, \rep, \advice)$ with distributional advice.  Let 
\[
\advice(Z) = \begin{cases} (\gen_Z, \rep_Z)& Z\in Z'\\\perp&\text{otherwise.}\end{cases}
\]
In both cases, $\advice(Z)$ has length at most $\ell$. Then define $\gen(x, C)$ as follows:  if $C = \perp$ sample a random key $r$ output $(r, r)$, otherwise interpret $C$ as two circuits $\gen', \rep'$ and output $\gen'(x)$.  Define $\rep(x, p, C)$ interpret $C$ if $C = \perp$ output $p$, otherwise parse $C$ as two circuits $\gen', \rep'$ and output $\rep'(x', p)$.  
Then 
\begin{align*}
\Delta((R, P, Z), (U_\kappa, P, Z)) &= \Delta((R, P, Z), (U_\kappa, P, Z) | Z\in Z')+\Delta((R, P, Z), (U_\kappa, P, Z) | Z\not\in Z')\\
&\le \frac{\epsilon-\zeta}{1-\zeta} * (1-\zeta) + 1* \zeta = \epsilon.
\end{align*}
It is clear that $(\gen, \rep, \advice)$ is a $(\mathcal{M}, \mathcal{W}, \kappa, t, \epsilon, \ell)$ fuzzy extractor with distributional advise.
\end{proof}

\paragraph{Interpretation} 
%We consider two natural settings where $\epsilon = \ngl(n)$ and when $\epsilon = \Theta(1)$.
%
%For the setting when $\epsilon = \ngl(n)$  if one sets $\zeta = \sqrt{\epsilon}$ this implies that for all subsets $\mathcal{W}' \subseteq \mathcal{W}$ where $\Pr[Z\in Z']\ge 1-\sqrt{\epsilon}.$ there is no $(\{0,1\}^n,\kappa, t, \sqrt{\epsilon}, \ell)$-fuzzy extractor for some element of $\mathcal{W}'$.  This shows that at least $\sqrt{\epsilon}$ fraction of elements in $\mathcal{W}$ do not have $(\{0,1\}^n,\kappa, t, \sqrt{\epsilon}, \ell)$-fuzzy extractors.
In the setting when $\epsilon = \Theta(1)$ then setting $\zeta = \epsilon/2$ implies that for all subsets $\mathcal{W}' \subseteq \mathcal{W}$ where $\Pr[Z\in Z']\ge 1-\epsilon/2 = 1-\Theta(1)$ there is no $(\{0,1\}^n,\kappa, t, \epsilon/(2-\epsilon), \ell)$-fuzzy extractor for some element of $\mathcal{W}'$.  This shows that at least $\epsilon/2=\Theta(1)$ fraction of elements in $\mathcal{W}$ do not have $(\{0,1\}^n,\kappa, t, \epsilon/(2-\epsilon), \ell)$-fuzzy extractors. This is the setting considered in Section~\ref{sec:fe}.


\begin{lemma}
Let $\mathcal{W}$ be a distribution family indexed by $Z$ and suppose that no $(\zo^n, \mathcal{W}, \tilde{m}, t, \epsilon, \delta, \ell)$-secure sketch with distributional advice exists.  For all families $\mathcal{W}'\subseteq \mathcal{W}$ indexed by $Z'\subseteq Z$ where\[\frac{|Z\cap Z'|}{|Z|} = \frac{|Z'|}{|Z|}\ge 1-2^{-\zeta}\]
there is some $Z'$ for which no  $(\zo^n, \min\{\tilde{m}, \zeta\}, t, \epsilon, \delta, \ell)$ fuzzy extractor $(\sketch_{Z'}, \rec_{Z'})$  exists.
\label{lem:distributional advise suffices ss}
\end{lemma}

\begin{proof}
The proof of Lemma~\ref{lem:distributional advise suffices ss} follows the structure of the proof of Lemma~\ref{lem:distributional advise suffices}.  With $ss=w$ and with the following equation for computing the remaining smooth conditional min-entropy.
\begin{align*}
\expe_{Z} [\Haveps(W_Z| \sketch(W_Z), Z)] &= -\log{\Pr[Z\in Z']\expe_{Z} 2^{-\Haveps(W_Z| ss, Z\in Z')}+ \Pr[Z\not\in Z']\expe_{Z} 2^{-\Haveps(W_Z| ss, Z\not\in Z'] }}\\
&\ge -\log{1 \cdot 2^{-\tilde{m}}+ 2^{-\zeta}\cdot 1}\\
&\ge -\log{2^{-\tilde{m}}+2^{-\zeta}}  \ge \min\{\tilde{m},\zeta\}.
\end{align*}
\end{proof}

\paragraph{Interpretation}
The natural parameter setting of the above is setting $\zeta = \max\{\tilde{m},1\} $ which shows that at least $2^{-\tilde{m}}$ of the distributions have no secure sketch.  Later in this work, we consider $\tilde{m} = \Theta(1)$ which suffices to that show that a constant fraction of distributions have no secure sketch.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
